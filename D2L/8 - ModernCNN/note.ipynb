{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd90a499-6125-477e-8c26-71913ff4d3ea",
   "metadata": {},
   "source": [
    "## Chapter 8 : Modern CNN\n",
    "1. **AlexNet**: first deep conv successful, using dropout, Relu, polling\n",
    "2. **VGG**: multiple 3 * 3 conv layers (two 3 * 3 conv touch 5 * 5 input as a 5 * 5 conv, but 2 * 3 * 3  = 18 < 25 = 5 * 5)\n",
    "3. **NiN**: to handle 2 problem (1. much ram for the MLP at the end; 2. can not add MLP between the conv to increase the degree of nonlinearity as it will destroy the spatial information)\n",
    "   - use 1 * 1 conv layer to add local nonlinearities across the channel activations\n",
    "   - use global average pooling to integrate across all locations in the last representation layer. (must combine with added nonlinearities)\n",
    "4. **GoogleNet**: Inception layer, parallel conv multi scales, and then concate them\n",
    "5. **Batch Normalization**:\n",
    "   - $BN(\\mathbf x) = \\mathbf{\\gamma} \\bigodot \\frac{\\mathbf x - \\mathbf{\\mu_B}}{\\sigma^2_B} + \\mathbf \\beta$, $\\mathbf{\\mu_B} = \\frac{1}{|B|}\\sum_{x \\in B} \\mathbf x$,\n",
    "     $\\sigma^2_B = \\frac{1}{|B|} \\sum_{x \\in B} (x - \\mathbf{\\mu_B})^2 + \\epsilon$\n",
    "   - On linear layer [N, D] it will get across D (different features in D will not do calculations), on conv layer [N, C, H, W] it will across C (save the difference between channels)\n",
    "     - For example, [N, C, H, W] shape input x, for x[N, 0, H, W], get it's mean mu and std and do (x[N, 0, H, W] - mu) / std, here mu and std are scalar.\n",
    "   - At the testing stage, we will use the global (whole) data mean and varience, instead of minibatch mean and varience. Just like dropout.\n",
    "   - So BN also serves as a noise introducer! (minibatch information != true mean and var) Teye et al. (2018) and Luo et al. (2018).\n",
    "   - So it best works for batch size of 50 ~ 100, higher the noise is small, lower it is too high.\n",
    "   - Moving global mean and var: when testing, no minibatch, so we use a global one that is stored during training.\n",
    "     - It is a kind of exp weighted mean, closest batch has higer weight\n",
    "     - $\\mu_m = \\mu_m * (1 - \\tau) + \\mu * \\tau, \\Sigma_m = \\Sigma_m * (1 - \\tau) + \\Sigma * \\tau$, $\\tau$ is called momentum term.\n",
    "6. **Layer Normalization**: often used in NLP\n",
    "   - For features like [N, A, B] it will save difference between N, A and B are typically seq_len, hidden_size.\n",
    "7. **ResNet**: residual block, pass x as one of the branch before a activation function (for the original paper, and later it is changed to BN -> AC -> Conv)\n",
    "   - To get the passed x has the correct shape to add up, we can use 1 * 1 conv if it is needed\n",
    "   - **Idea**: nested-function class, shallower net (like ResNet-20) is subclass of depper net (like ResNet-50). Because in ResNet-50 if the layers after 20th layer are f(x) = x, then it is the same as RestNet-20! So we can make sure f' (the best we can get in ResNet-50 for certain data) will be better than f (ResNet-20 on the same data) or at least the same.\n",
    "   - <p align=\"center\">\n",
    "       <img alt=\"Residul Block\" src=\"https://d2l.ai/_images/resnet-block.svg\" style=\"background-color: white; display: inline-block;\">\n",
    "       Rusidul Block\n",
    "   </p>\n",
    "   - **ResNeXt**: use g groups of 3 * 3 conv layers between two 1 * 1 conv of channel $b$ and $c_o$, so $\\mathcal O(c_i c_o) \\rightarrow \\mathcal O(g ~ c_i / g ~ c_o / g) = \\mathcal O(c_ic_o/g)$\n",
    "     - This is a **Bottleneck** arch if $b < c_i$\n",
    "       </br>\n",
    "   - <img alt=\"ResNeXt Block\" src=\"https://d2l.ai/_images/resnext-block.svg\" style=\"background-color: white; display: inline-block;\">\n",
    "       ResNeXt Block\n",
    "8. **DenseNet**: instead of plus x, we concatenate x repeatedly.\n",
    "   - For example (\\<channel\\> indicates the channel): x\\<c_1\\> -> f_1(x)\\<c_2\\> end up with [x, f_1(x)]\\<c_1 + c_2\\> -> f_2([x, f_1(x)])\\<c_3\\> end up with [x, f_1(x), f_2([x, f_1(x)])]\\<c_1 + c_2 + c_3\\>\n",
    "   - Too many of this layer will cause the dimeansion too big, so we need some layer to reduce it. **Translation** layer use 1 * 1 conv to reduce channel and avgpool to half the H and W.\n",
    "9. **RegNet**:\n",
    "   - AnyNet: network with **stem** -> **body** -> **head**.\n",
    "   - Distrubution of net: $F(e,Z)=∑_{i=1}^{n}1(e_i<e)$, use this empirical CDF to approximate $F(e, p)$, $p$ is the net arch distrubution. $Z$ is a sample of net sample from $p$, if $F(e, Z_1) < F(e, Z_2)$ then we say $Z_1$ is better, it's parameters are better.\n",
    "   - So for RegNet, they find that we should use same k (k = 1, no bottlenet, is best, says in paper) and g for the ResNeXt blocks with no harm, and increase the network depth d and weight c along the stage. And keep the c change linearly with $c_j = c_o + c_aj$ with slope $c_a$\n",
    "   - neural architecture search (NAS) : with certain search space, use RL (NASNet), evolution alg (AmoebaNet), gradient based (DARTS) or shared weight (ENAS) to get the model. But it takes to much computation resource.\n",
    "   - <img src=\"https://d2l.ai/_images/anynet.svg\" style=\"background-color: white; display: inline-block;\"> AnyNet Structure\n",
    "   - End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2415773-c09a-40cb-b65e-88242ead5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eede0e3d-7af9-4850-b589-7ce0b5871f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_summary(net, X_shape):\n",
    "        \"\"\"Defined in :numref:`sec_lenet`\"\"\"\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in net:\n",
    "            X = layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62badd5a-2fbb-480a-aff1-1b9b54bf678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.LazyConv2d(out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5676e095-8a71-4e4d-9a8d-20845ab72490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(module):\n",
    "    \"\"\"Initialize weights for CNNs.\n",
    "\n",
    "    Defined in :numref:`sec_lenet`\"\"\"\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b63d4a6-8d0c-4c1f-983f-5ce4d1281472",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        conv_blks = []\n",
    "        for (num_convs, out_channels) in arch:\n",
    "            conv_blks.append(vgg_block(num_convs, out_channels))\n",
    "        self.net = nn.Sequential(\n",
    "            *conv_blks, nn.Flatten(),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.LazyLinear(num_classes))\n",
    "        self.net.apply(init_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0fbf563-aa52-4965-8019-698c79f851d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_11 = VGG(arch=((1, 64), (1, 128), (2, 256), (2, 512), (2, 512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2efccb60-bf7c-4cd0-a179-6c1d428db8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([32, 64, 112, 112])\n",
      "Sequential output shape:\t torch.Size([32, 128, 56, 56])\n",
      "Sequential output shape:\t torch.Size([32, 256, 28, 28])\n",
      "Sequential output shape:\t torch.Size([32, 512, 14, 14])\n",
      "Sequential output shape:\t torch.Size([32, 512, 7, 7])\n",
      "Flatten output shape:\t torch.Size([32, 25088])\n",
      "Linear output shape:\t torch.Size([32, 4096])\n",
      "ReLU output shape:\t torch.Size([32, 4096])\n",
      "Dropout output shape:\t torch.Size([32, 4096])\n",
      "Linear output shape:\t torch.Size([32, 4096])\n",
      "ReLU output shape:\t torch.Size([32, 4096])\n",
      "Dropout output shape:\t torch.Size([32, 4096])\n",
      "Linear output shape:\t torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "layer_summary(VGG_11.net, (32, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa9265ab-5d11-4591-898b-478e07b279d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin_block(out_channels, kernel_size, strides, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.LazyConv2d(out_channels, kernel_size, strides, padding), nn.ReLU(),\n",
    "        nn.LazyConv2d(out_channels, kernel_size=1), nn.ReLU(),\n",
    "        nn.LazyConv2d(out_channels, kernel_size=1), nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae5c5b57-df82-4a4d-b601-8c63920fb571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([32, 5, 224, 224])\n",
      "ReLU output shape:\t torch.Size([32, 5, 224, 224])\n",
      "Conv2d output shape:\t torch.Size([32, 5, 224, 224])\n",
      "ReLU output shape:\t torch.Size([32, 5, 224, 224])\n",
      "Conv2d output shape:\t torch.Size([32, 5, 224, 224])\n",
      "ReLU output shape:\t torch.Size([32, 5, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "nin_block_ = nin_block(5, (3,3), 1, 1)\n",
    "layer_summary(nin_block_, (32, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0698882c-cb43-474e-b593-67ae936b5469",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiN(nn.Module):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nin_block(96, kernel_size=11, strides=4, padding=0),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nin_block(256, kernel_size=5, strides=1, padding=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nin_block(384, kernel_size=3, strides=1, padding=1),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "            nin_block(num_classes, kernel_size=3, strides=1, padding=1),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2b8989f-7b5f-408a-80df-9f7f09bac211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([32, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([32, 96, 26, 26])\n",
      "Sequential output shape:\t torch.Size([32, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([32, 256, 12, 12])\n",
      "Sequential output shape:\t torch.Size([32, 384, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([32, 384, 5, 5])\n",
      "Dropout output shape:\t torch.Size([32, 384, 5, 5])\n",
      "Sequential output shape:\t torch.Size([32, 10, 5, 5])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([32, 10, 1, 1])\n",
      "Flatten output shape:\t torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "nin = NiN()\n",
    "layer_summary(nin.net, (32, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56f874a5-135c-489a-9b24-1e3288827359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class Inception(nn.Module):\n",
    "    # c1--c4 are the number of output channels for each branch\n",
    "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        # Branch 1\n",
    "        self.b1_1 = nn.LazyConv2d(c1, kernel_size=1)\n",
    "        # Branch 2\n",
    "        self.b2_1 = nn.LazyConv2d(c2[0], kernel_size=1)\n",
    "        self.b2_2 = nn.LazyConv2d(c2[1], kernel_size=3, padding=1)\n",
    "        # Branch 3\n",
    "        self.b3_1 = nn.LazyConv2d(c3[0], kernel_size=1)\n",
    "        self.b3_2 = nn.LazyConv2d(c3[1], kernel_size=5, padding=2)\n",
    "        # Branch 4\n",
    "        self.b4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.b4_2 = nn.LazyConv2d(c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b1 = F.relu(self.b1_1(x))\n",
    "        b2 = F.relu(self.b2_2(F.relu(self.b2_1(x))))\n",
    "        b3 = F.relu(self.b3_2(F.relu(self.b3_1(x))))\n",
    "        b4 = F.relu(self.b4_2(self.b4_1(x)))\n",
    "        return torch.cat((b1, b2, b3, b4), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec612d10-946a-40f9-b464-28534a88e124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'b1_1': Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1)),\n",
       "  'b2_1': Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1)),\n",
       "  'b2_2': Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'b3_1': Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1)),\n",
       "  'b3_2': Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n",
       "  'b4_1': MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False),\n",
       "  'b4_2': Conv2d(3, 128, kernel_size=(1, 1), stride=(1, 1))},\n",
       " torch.Size([32, 232, 224, 224]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incep = Inception(8, (16, 32), (32, 64), 128)\n",
    "incep.eval()._modules, incep(torch.randn(32, 3, 224, 224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54e7bbfe-5ec2-45db-9a4e-9fdbddf708cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super(GoogleNet, self).__init__()\n",
    "        self.net = nn.Sequential(self.b1(), self.b2(), self.b3(), self.b4(),\n",
    "                                 self.b5(), nn.LazyLinear(num_classes))\n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    def b2(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(192, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    def b3(self):\n",
    "        return nn.Sequential(Inception(64, (96, 128), (16, 32), 32),\n",
    "                             Inception(128, (128, 192), (32, 96), 64),\n",
    "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    def b4(self):\n",
    "        return nn.Sequential(Inception(192, (96, 208), (16, 48), 64),\n",
    "                             Inception(160, (112, 224), (24, 64), 64),\n",
    "                             Inception(128, (128, 256), (24, 64), 64),\n",
    "                             Inception(112, (144, 288), (32, 64), 64),\n",
    "                             Inception(256, (160, 320), (32, 128), 128),\n",
    "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    def b5(self):\n",
    "        return nn.Sequential(Inception(256, (160, 320), (32, 128), 128),\n",
    "                             Inception(384, (192, 384), (48, 128), 128),\n",
    "                             nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9e3c9e1-2941-4b40-909a-232bf6f1b922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([32, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([32, 192, 28, 28])\n",
      "Sequential output shape:\t torch.Size([32, 480, 14, 14])\n",
      "Sequential output shape:\t torch.Size([32, 832, 7, 7])\n",
      "Sequential output shape:\t torch.Size([32, 1024])\n",
      "Linear output shape:\t torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "g = GoogleNet()\n",
    "layer_summary(g.net, (32, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddeab0bc-9e80-4ff8-82d8-c9f341b5b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    # 通过is_grad_enabled来判断当前模式是训练模式还是预测模式\n",
    "    if not torch.is_grad_enabled():\n",
    "        print(\"In testing:\")\n",
    "        # 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        print(\"In training:\")\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            # 使用全连接层的情况，计算特征维上的均值和方差\n",
    "            print(\"For full connect layer:\")\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "            print(\"mean, var are: \", mean, var)\n",
    "        else:\n",
    "            print(\"For conv layer:\")\n",
    "            # 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。\n",
    "            # 这里我们需要保持X的形状以便后面可以做广播运算\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "            print(\"mean, var are: \", mean, var)\n",
    "            print(\"X - mean\", X - mean)\n",
    "        # 训练模式下，用当前的均值和方差做标准化\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # 更新移动平均的均值和方差\n",
    "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
    "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
    "    Y = gamma * X_hat + beta  # 缩放和移位\n",
    "    return Y, moving_mean.data, moving_var.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "13dad273-13ea-490d-b387-137dd33355f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_3d is :\n",
      " tensor([[[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.]]])\n",
      "x_4d is :\n",
      " tensor([[[[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2.],\n",
      "          [2., 2.]],\n",
      "\n",
      "         [[3., 3.],\n",
      "          [3., 3.]]]])\n"
     ]
    }
   ],
   "source": [
    "x_3d = torch.zeros(2, 2, 2)\n",
    "x_3d[1, :, :] = 1\n",
    "x_4d = torch.zeros(2, 2, 2, 2)\n",
    "x_4d[0, 1, :, :] = 1\n",
    "x_4d[1, 0, :, :] = 2\n",
    "x_4d[1, 1, :, :] = 3\n",
    "print(\"x_3d is :\\n\", x_3d)\n",
    "print(\"x_4d is :\\n\", x_4d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aad211f4-6cda-4d1e-af00-19a53868eae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is BN: across the channel\n",
      "In training:\n",
      "For conv layer:\n",
      "mean, var are:  tensor([[[[1.]],\n",
      "\n",
      "         [[2.]]]]) tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "X - mean tensor([[[[-1., -1.],\n",
      "          [-1., -1.]],\n",
      "\n",
      "         [[-1., -1.],\n",
      "          [-1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  1.],\n",
      "          [ 1.,  1.]],\n",
      "\n",
      "         [[ 1.,  1.],\n",
      "          [ 1.,  1.]]]])\n",
      "tensor([[[-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000]],\n",
      "\n",
      "        [[ 1.0000,  1.0000],\n",
      "         [ 1.0000,  1.0000]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1., -1.],\n",
       "         [-1., -1.]],\n",
       "\n",
       "        [[ 1.,  1.],\n",
       "         [ 1.,  1.]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"This is BN: across the channel: no between channel calculations\")\n",
    "print(batch_norm(x_4d, 1, 0, 0, 1, 1e-6, 0.1)[0][:, 0, :, :])\n",
    "(x_4d[:, 0, :, :] - (x_4d[:, 0, :, :]).mean()) / torch.std(x_4d[:, 0, :, :], unbiased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ae5ea75b-293a-44d7-83af-71d799fb9a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1., -1.],\n",
      "          [-1., -1.]],\n",
      "\n",
      "         [[ 1.,  1.],\n",
      "          [ 1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1.],\n",
      "          [-1., -1.]],\n",
      "\n",
      "         [[ 1.,  1.],\n",
      "          [ 1.,  1.]]]])\n",
      "tensor([[[[-1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000]]]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print((x_4d - x_4d.mean(dim=(1, 2, 3), keepdim=True)) / x_4d.std(dim=(1, 2, 3), keepdim=True, unbiased=False)) # Impl of layer normal \n",
    "print(nn.LayerNorm((2, 2, 2))(x_4d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebb32f06-933b-4522-9abb-877c63edf267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):  #@save\n",
    "    \"\"\"The Residual block of ResNet models.\"\"\"\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n",
    "                                   stride=strides)\n",
    "        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
    "                                       stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.LazyBatchNorm2d()\n",
    "        self.bn2 = nn.LazyBatchNorm2d()\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43ad6afc-0c0d-4e13-92ca-ada14083ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(self.b1())\n",
    "        for i, b in enumerate(arch):\n",
    "            self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))\n",
    "        self.net.add_module('last', nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
    "            nn.LazyLinear(num_classes)))\n",
    "        \n",
    "    def block(self, num_residuals, num_channels, first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(Residual(num_channels))\n",
    "        return nn.Sequential(*blk)\n",
    "    \n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fb55619-fb72-44d3-b8d5-4b10b56232f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([32, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([32, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([32, 128, 28, 28])\n",
      "Sequential output shape:\t torch.Size([32, 256, 14, 14])\n",
      "Sequential output shape:\t torch.Size([32, 512, 7, 7])\n",
      "Sequential output shape:\t torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "resnet = ResNet(((2, 64), (2, 128), (2, 256), (2, 512)))\n",
    "layer_summary(resnet.net, (32, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357c7b3-0637-410a-bf6c-7d292fab9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNeXtBlock(nn.Module):  #@save\n",
    "    \"\"\"The ResNeXt block.\"\"\"\n",
    "    def __init__(self, num_channels, groups, bot_mul, use_1x1conv=False,\n",
    "                 strides=1):\n",
    "        super().__init__()\n",
    "        bot_channels = int(round(num_channels * bot_mul))\n",
    "        self.conv1 = nn.LazyConv2d(bot_channels, kernel_size=1, stride=1)\n",
    "        self.conv2 = nn.LazyConv2d(bot_channels, kernel_size=3,\n",
    "                                   stride=strides, padding=1,\n",
    "                                   groups=bot_channels//groups)\n",
    "        self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1, stride=1)\n",
    "        self.bn1 = nn.LazyBatchNorm2d()\n",
    "        self.bn2 = nn.LazyBatchNorm2d()\n",
    "        self.bn3 = nn.LazyBatchNorm2d()\n",
    "        if use_1x1conv:\n",
    "            self.conv4 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
    "                                       stride=strides)\n",
    "            self.bn4 = nn.LazyBatchNorm2d()\n",
    "        else:\n",
    "            self.conv4 = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = F.relu(self.bn2(self.conv2(Y)))\n",
    "        Y = self.bn3(self.conv3(Y))\n",
    "        if self.conv4:\n",
    "            X = self.bn4(self.conv4(X))\n",
    "        return F.relu(Y + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e6be857-d9c2-49ff-aaa0-3a9672bea000",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dense Net\n",
    "\"\"\"\n",
    "def conv_block(num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "        nn.LazyConv2d(num_channels, kernel_size=3, padding=1))\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_convs, num_channels):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layer = []\n",
    "        for i in range(num_convs):\n",
    "            layer.append(conv_block(num_channels))\n",
    "        self.net = nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for blk in self.net:\n",
    "            Y = blk(X)\n",
    "            # Concatenate input and output of each block along the channels\n",
    "            X = torch.cat((X, Y), dim=1)\n",
    "        return X\n",
    "\n",
    "def transition_block(num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "        nn.LazyConv2d(num_channels, kernel_size=1),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, num_channels=64, growth_rate=32, arch=(4, 4, 4, 4),\n",
    "             lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        # self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(self.b1())\n",
    "        for i, num_convs in enumerate(arch):\n",
    "            self.net.add_module(f'dense_blk{i+1}', DenseBlock(num_convs,\n",
    "                                                              growth_rate))\n",
    "            # The number of output channels in the previous dense block\n",
    "            num_channels += num_convs * growth_rate\n",
    "            # A transition layer that halves the number of channels is added\n",
    "            # between the dense blocks\n",
    "            if i != len(arch) - 1:\n",
    "                num_channels //= 2\n",
    "                self.net.add_module(f'tran_blk{i+1}', transition_block(\n",
    "                    num_channels))\n",
    "        self.net.add_module('last', nn.Sequential(\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
    "            nn.LazyLinear(num_classes)))\n",
    "        # self.net.apply(d2l.init_cnn)\n",
    "        \n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cda044a-5d22-477d-8d1d-55053795bbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([32, 64, 56, 56])\n",
      "DenseBlock output shape:\t torch.Size([32, 192, 56, 56])\n",
      "Sequential output shape:\t torch.Size([32, 96, 28, 28])\n",
      "DenseBlock output shape:\t torch.Size([32, 224, 28, 28])\n",
      "Sequential output shape:\t torch.Size([32, 112, 14, 14])\n",
      "DenseBlock output shape:\t torch.Size([32, 240, 14, 14])\n",
      "Sequential output shape:\t torch.Size([32, 120, 7, 7])\n",
      "DenseBlock output shape:\t torch.Size([32, 248, 7, 7])\n",
      "Sequential output shape:\t torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "dense = DenseNet()\n",
    "layer_summary(dense.net, (32, 3, 224, 224))\n",
    "\"\"\"\n",
    "[32, 64, 56, 56] -> 64 will become 192 = 64 + 32 (growth_rate) * 4 (num_conv)\n",
    "Then will a transition layer 192 -> 192 / 2 = 96, 56 -> 56 / 2 = 18\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924a3f8a-afbe-4c9d-abac-c76736a80f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
