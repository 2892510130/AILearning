{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd007899-8342-4932-9a76-b0629d93dbc4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Auto Grad Notes\n",
    "- What is a **leaf node**? Data create by the user, compare with date computed.\n",
    "  For example, x = tensor(), y = x.dot(x), then x is leaf node, y is not.\n",
    "- Non leaf node will not store grad, it will store **grad_fn** (y store a Mul fn) for the backward compute, but you can do y.retain_grad() to store it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320dbd42-1713-4dcc-9854-01b6c12f6c79",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Pytorch Notes\n",
    "- default is **torch.float32**\n",
    "- torch.var and std use a unbiased estimate\n",
    "- CrossEntropyLoss take target as indices of shape (-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac4a9eb-fcce-416e-ab8a-a45be42b5a1d",
   "metadata": {},
   "source": [
    "## Trainning Tips Notes\n",
    "- **Generalization**\n",
    "    1. corss valid or K-fold valid\n",
    "    2. more complicated model, more data needed, see [cross](\"https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#crossentropyloss\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7f04d-e677-4504-bdd2-65859eb630ef",
   "metadata": {},
   "source": [
    "## History of CV\n",
    "1. AlexNet (2012): Relu, Dropout, GPU, Deep Conv Net\n",
    "2. VGGNet (2014): Deeper Net and smaller kerner\n",
    "3. GoogLeNet (Inception v1, 2014): Inception -> multi scale kernel, 1 * 1 kernel\n",
    "4. ResNet (2015)\n",
    "5. Object Detection:\n",
    "   - R-CNN\n",
    "   - YOLO\n",
    "   - SSD\n",
    "6. Segment:\n",
    "   - FCN (2015)\n",
    "   - U-Net (2015): encoder - decoder\n",
    "   - DeepLab: Atrous Convolution, Atrous Spatial Pyramid Pooling\n",
    "7. Generation:\n",
    "   - GAN (2014)\n",
    "   - SytleGAN (2019): style transfer\n",
    "8. Non-supervised\n",
    "   - MoCo (2020)\n",
    "   - SimCLR (2020)\n",
    "9. Transformer:\n",
    "    - ViT (2020): first on CV\n",
    "    - Swin Transformer (2021): for dection and segment\n",
    "10. Trend:\n",
    "    - MultiModule: CLIP, DALL-E\n",
    "    - 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8533f4f-7d0f-4dee-ae53-fb24a27de11f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
