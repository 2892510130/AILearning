{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9739bc-46fa-4a82-8316-135a2296afe7",
   "metadata": {},
   "source": [
    "## Chapter 6: Beginner Guide\n",
    "- Tied layer: gradient will add up along different chain\n",
    "- Custom initialization: `apply` method\n",
    "- I/O\n",
    "  - save tensor: `torch.save(x:Uinon[List[tensor], Dict], name:str)` and load\n",
    "  - save model: the same, just input dict of the net (`net.state_dict()`) then `net.load_state_dict(torch.load(name))`\n",
    "- GPU\n",
    "  - operation between tensors must in the same GPU\n",
    "  - print or transform to numpy will copy to memory, and even worse wait the python **GIL** (`Global Interpreter Lock`, make sure at the same time only one thread can execute the python bytecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92fabaec-5aa1-4493-b250-9a70384c9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11dea4e1-6a42-44db-a024-a2da75cff9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TiedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        linear_layer = nn.LazyLinear(32)\n",
    "        # self.net = nn.Sequential(linear_layer, nn.ReLU(),\n",
    "        #                          linear_layer, nn.ReLU(),\n",
    "        #                          nn.LazyLinear(1))\n",
    "        self.net = nn.Sequential(nn.LazyLinear(32), nn.ReLU(),\n",
    "                                 linear_layer, nn.ReLU(),\n",
    "                                 linear_layer, nn.ReLU(),)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "351c87f9-8a5a-44b9-b55b-93001e2afd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UninitializedParameter>\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 32])\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (5): ReLU()\n",
      ")\n",
      "torch.Size([32, 2])\n",
      "0\n",
      "torch.Size([32, 32])\n",
      "tensor([[ 0.9961,  0.0979,  0.0000,  ...,  0.1630,  0.0000,  0.5559],\n",
      "        [-0.2359,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.6810,  0.0979,  0.0000,  ...,  0.1630,  0.0000,  0.5559],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9429,  0.0979,  0.0000,  ...,  0.1630,  0.0000,  0.5559]])\n",
      "tensor([[ 0.9961,  0.0979,  0.0000,  ...,  0.1630,  0.0000,  0.5559],\n",
      "        [-0.2359,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.6810,  0.0979,  0.0000,  ...,  0.1630,  0.0000,  0.5559],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.9429,  0.0979,  0.0000,  ...,  0.1630,  0.0000,  0.5559]])\n"
     ]
    }
   ],
   "source": [
    "tied_model = TiedModel()\n",
    "print(tied_model.net[2].weight)\n",
    "data = torch.tensor([1, 2.0]).reshape(1, -1)\n",
    "data.requires_grad_(True)\n",
    "print(data.shape)\n",
    "\n",
    "output = tied_model(data)\n",
    "print(output.shape)\n",
    "output.sum().backward()\n",
    "print(tied_model.net)\n",
    "\n",
    "print(tied_model.net[0].weight.grad.shape)\n",
    "print(tied_model.net[1].state_dict().__len__()) # no weight\n",
    "print(tied_model.net[2].weight.grad.shape)\n",
    "print(tied_model.net[2].weight.grad) # 2 and 4 grad is the same\n",
    "print(tied_model.net[4].weight.grad) # 2 and 4 grad is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2fd2c06-070d-4e56-a229-a8744e92bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normal(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        nn.init.normal_(module.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e59fab06-b3cf-4e07-ae42-41301db4638e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0079, -0.0104, -0.0116,  0.0134, -0.0147, -0.0072, -0.0090, -0.0035,\n",
      "         0.0137, -0.0168,  0.0012, -0.0099, -0.0054,  0.0072, -0.0045, -0.0135,\n",
      "         0.0071,  0.0014,  0.0197, -0.0017,  0.0031,  0.0025, -0.0042, -0.0049,\n",
      "        -0.0184, -0.0064, -0.0088, -0.0035, -0.0220,  0.0105, -0.0146,  0.0110])\n",
      "tensor([ 1.5377e-02, -1.7294e-02,  5.9649e-04, -2.4361e-03, -6.4072e-03,\n",
      "         5.3947e-03,  3.9172e-03,  5.6747e-03, -2.8256e-04,  1.3490e-02,\n",
      "         4.2003e-03,  8.5548e-03,  6.0128e-03, -1.4819e-03, -2.2291e-03,\n",
      "         1.3369e-02, -1.3220e-02,  1.2654e-03, -4.5651e-03,  1.8961e-02,\n",
      "        -1.1517e-02, -8.9003e-03,  5.3294e-03, -4.2507e-03,  2.2758e-05,\n",
      "        -9.9561e-03,  2.2119e-03,  3.3493e-03,  5.2531e-05, -1.1092e-02,\n",
      "        -2.8326e-04,  1.1497e-02])\n"
     ]
    }
   ],
   "source": [
    "print(tied_model.net[2].weight.data[0])\n",
    "tied_model.net[2].apply(init_normal)\n",
    "print(tied_model.net[2].weight.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "328200c5-944c-47fa-900e-0fc3cd8c7559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[12., 16.],\n",
      "        [12., 16.]])\n",
      "tensor([[10., 12.],\n",
      "        [10., 12.]], grad_fn=<AddBackward0>)\n",
      "tensor([[1., 1.],\n",
      "        [2., 2.]], requires_grad=True)\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[3., 3.],\n",
      "        [5., 5.]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 8.,  8.],\n",
      "        [16., 16.]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Try to understand tied module\n",
    "\"\"\"\n",
    "a = torch.tensor([[1, 1.0], [2, 2.0]])\n",
    "a.requires_grad_(True)\n",
    "x = torch.ones((2, 2))\n",
    "y = a @ x + 1\n",
    "y.retain_grad()\n",
    "z = a @ y\n",
    "\n",
    "# z.backward(torch.ones_like(a))\n",
    "z.sum().backward()\n",
    "\n",
    "print(y.grad)\n",
    "print(a.grad)\n",
    "print(2 * a.T @ x.T + torch.ones((2, 2)) + y.T)\n",
    "print(a)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "64586c92-faca-42fb-b69e-d6699a245396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.ones((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5dab4dd2-48d4-4d41-bbbd-950d6a02a568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[1., 1.],\n",
      "        [2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "new_y = torch.tensor([[3., 3.],\n",
    "        [5., 5.]])\n",
    "new_y.requires_grad_(True)\n",
    "new_a = torch.tensor([[1, 1.0], [2, 2.0]])\n",
    "new_z = new_a @ new_y\n",
    "new_z.backward(torch.ones_like(new_z))\n",
    "print(new_y.grad)\n",
    "print(torch.ones_like(new_z) @ new_a)\n",
    "print(new_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1d8ad3b8-4937-45de-a3e4-d912485fce51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "second_y = torch.tensor([[3., 3.],\n",
    "        [5., 5.]])\n",
    "second_y.requires_grad_(True)\n",
    "second_z = second_y.sum()\n",
    "second_z.backward()\n",
    "print(second_y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f542b625-c04f-41b5-b8f1-da0925e85a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 27 02:06:11 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.67                 Driver Version: 536.67       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060      WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   42C    P8              52W / 115W |   1286MiB /  8188MiB |      8%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1648    C+G   ...\\bin-7.2.5\\Nutstore.WindowsHook.exe    N/A      |\n",
      "|    0   N/A  N/A      3948    C+G   ...tstore\\bin-7.2.5\\NutstoreClient.exe    N/A      |\n",
      "|    0   N/A  N/A      5408    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      7728    C+G   ...\\Tools\\v2rayN-windows-64\\v2rayN.exe    N/A      |\n",
      "|    0   N/A  N/A      8004    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      9500    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9524    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10148    C+G   ...m Files\\Mozilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A     11208    C+G   ...m Files\\Mozilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A     12276    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     12716    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     13432    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14264    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15192    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     19960    C+G   ...cent\\QQGuild\\9.7.22-513\\QQGuild.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83a9c5af-438e-4073-b2ce-2651a92b955c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6940789222717285"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "a_cpu = torch.randn((500, 500))\n",
    "b_cpu = torch.randn((500, 500))\n",
    "for i in range(10000):\n",
    "    a_cpu @= b_cpu\n",
    "t2 = time.time()\n",
    "(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e762ba96-db61-413f-b613-4f7ed2a5d9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.669034481048584"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "a_gpu = torch.randn((500, 500), device=\"cuda:0\")\n",
    "b_gpu = torch.randn((500, 500), device=\"cuda:0\")\n",
    "for i in range(10000):\n",
    "    a_gpu @= b_gpu\n",
    "t2 = time.time()\n",
    "(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2cafb5-30e8-4645-ab85-0aab7a53d843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
